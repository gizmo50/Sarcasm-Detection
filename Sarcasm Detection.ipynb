{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            headline  is_sarcastic  \\\n",
      "0                           sab first class hai bhai             1   \n",
      "1  former versace store clerk sues over secret 'b...             0   \n",
      "2  the 'roseanne' revival catches up to our thorn...             0   \n",
      "3  mom starting to fear son's web series closest ...             1   \n",
      "4  boehner just wants wife to listen, not come up...             1   \n",
      "\n",
      "                                        article_link  \n",
      "0                                                NaN  \n",
      "1  https://www.huffingtonpost.com/entry/versace-b...  \n",
      "2  https://www.huffingtonpost.com/entry/roseanne-...  \n",
      "3  https://local.theonion.com/mom-starting-to-fea...  \n",
      "4  https://politics.theonion.com/boehner-just-wan...  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_json(\"Sarcasm.json\", lines=True)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            headline is_sarcastic  \\\n",
      "0                           sab first class hai bhai      Sarcasm   \n",
      "1  former versace store clerk sues over secret 'b...  Not Sarcasm   \n",
      "2  the 'roseanne' revival catches up to our thorn...  Not Sarcasm   \n",
      "3  mom starting to fear son's web series closest ...      Sarcasm   \n",
      "4  boehner just wants wife to listen, not come up...      Sarcasm   \n",
      "\n",
      "                                        article_link  \n",
      "0                                                NaN  \n",
      "1  https://www.huffingtonpost.com/entry/versace-b...  \n",
      "2  https://www.huffingtonpost.com/entry/roseanne-...  \n",
      "3  https://local.theonion.com/mom-starting-to-fea...  \n",
      "4  https://politics.theonion.com/boehner-just-wan...  \n"
     ]
    }
   ],
   "source": [
    "data[\"is_sarcastic\"] = data[\"is_sarcastic\"].map({0: \"Not Sarcasm\", 1: \"Sarcasm\"})\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"headline\", \"is_sarcastic\"]]\n",
    "x = np.array(data[\"headline\"])\n",
    "y = np.array(data[\"is_sarcastic\"])\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(x) # Fit the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8496817671284164\n"
     ]
    }
   ],
   "source": [
    "model = BernoulliNB()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a Text: mera head ghoom raha hai\n",
      "['Sarcasm']\n"
     ]
    }
   ],
   "source": [
    "user = input(\"Enter a Text: \")\n",
    "data = cv.transform([user]).toarray()\n",
    "output = model.predict(data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement google-collab (from versions: none)\n",
      "ERROR: No matching distribution found for google-collab\n"
     ]
    }
   ],
   "source": [
    "pip install google-collab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
