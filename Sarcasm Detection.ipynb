{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            headline  is_sarcastic  \\\n",
      "0                           sab first class hai bhai             1   \n",
      "1  former versace store clerk sues over secret 'b...             0   \n",
      "2  the 'roseanne' revival catches up to our thorn...             0   \n",
      "3  mom starting to fear son's web series closest ...             1   \n",
      "4  boehner just wants wife to listen, not come up...             1   \n",
      "\n",
      "                                        article_link  \n",
      "0                                                NaN  \n",
      "1  https://www.huffingtonpost.com/entry/versace-b...  \n",
      "2  https://www.huffingtonpost.com/entry/roseanne-...  \n",
      "3  https://local.theonion.com/mom-starting-to-fea...  \n",
      "4  https://politics.theonion.com/boehner-just-wan...  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_json(\"Sarcasm.json\", lines=True)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   article_link  is_sarcastic  \\\n",
      "0             0             0   \n",
      "1             1             0   \n",
      "2             2             1   \n",
      "3             3             1   \n",
      "4             4             1   \n",
      "\n",
      "                                            headline  \n",
      "0  ather farouqui general secretary of ghar empha...  \n",
      "1  by passing of is started ji jaggo nahi to sama...  \n",
      "2  swadu duniya geeta parjapat manjeetgill royal ...  \n",
      "3  hurry up kahin ye offer miss na ho jaye p p p p p  \n",
      "4  s logic hasne ke paise milte hai to alag alag ...  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_json(\"Dataset.json\", orient = 'records', dtype={\"article_link\":int, \"is_sarcastic\":int,\"headline\":str})\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   article_link is_sarcastic  \\\n",
      "0             0  Not Sarcasm   \n",
      "1             1  Not Sarcasm   \n",
      "2             2      Sarcasm   \n",
      "3             3      Sarcasm   \n",
      "4             4      Sarcasm   \n",
      "\n",
      "                                            headline  \n",
      "0  ather farouqui general secretary of ghar empha...  \n",
      "1  by passing of is started ji jaggo nahi to sama...  \n",
      "2  swadu duniya geeta parjapat manjeetgill royal ...  \n",
      "3  hurry up kahin ye offer miss na ho jaye p p p p p  \n",
      "4  s logic hasne ke paise milte hai to alag alag ...  \n"
     ]
    }
   ],
   "source": [
    "data[\"is_sarcastic\"] = data[\"is_sarcastic\"].map({0: \"Not Sarcasm\", 1: \"Sarcasm\"})\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"headline\", \"is_sarcastic\"]]\n",
    "x = np.array(data[\"headline\"])\n",
    "y = np.array(data[\"is_sarcastic\"])\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(x) # Fit the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bernoulli Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.786695652173913\n"
     ]
    }
   ],
   "source": [
    "model = BernoulliNB()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a Text: bhai money ki baarish ho rahi hai\n",
      "['Sarcasm']\n"
     ]
    }
   ],
   "source": [
    "user = input(\"Enter a Text: \")\n",
    "data = cv.transform([user]).toarray()\n",
    "output = model.predict(data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
